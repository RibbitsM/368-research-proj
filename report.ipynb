{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Project Midway Point (Healthcare & Technology)\n",
    "\n",
    "### Adam Walmsley Rowan Murphy\n",
    "\n",
    "#### Link to github: https://github.com/RibbitsM/368-research-proj/tree/main\n",
    "\n",
    "### March 12th, 2025\n",
    "\n",
    "##### AI Tool Use Declaration:\n",
    "ChatGPT was used to aid with some of the data cleaning steps for this project. Specific Prompts included:\n",
    "- 'How to replace names from a data frame with others'\n",
    "- 'How to pivot a data frame'\n",
    "- 'How to plot groups of data'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Summary\n",
    "\n",
    "In this project we are looking at how healthcare spending in Canada changes between provincial government parties and how effective their policies are at having a high quality, functioning healthcare system. Our ultimate goal is to diagnose the success of the various parties in Canada to get an unbiased view of how important the public healthcare system is to each party respectively, as well as diagnose the inequalities between provinces not accounting for parties in control."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Questions\n",
    "\n",
    "We have two members in our group and thus two distinct research questions, they are as follows:\n",
    "\n",
    "1. With what level of importance do the different provincial government parties give to healthcare spending and is there one party that clearly cares more about public healthcare?\n",
    "\n",
    "2. Which province has the most efficient healthcare spending?\n",
    "\n",
    "We did not tweak our research questions much since the initial proposal. This is because we felt they were adequate and our TA had no problems whatsoever with them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning Steps\n",
    "\n",
    "The following code and discussion will walk through our data cleaning process for all data sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by importing the necessary libraries to enable our data cleaning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Set 1: Provincial Governments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first data set to tackle is provincial_governments_2000_2024.csv. We made this data set ourselves after compiling historical data for provincial governments in power since 2000. The data set contains data on BC, Alberta, Ontario and Quebec only. We kept the parties specific names in, and there exist the following distinct parties in the dataset:\n",
    "\n",
    "- NDP\n",
    "- BC Liberal Party\n",
    "- Progressive Conservative Party\n",
    "- United Conservative Party\n",
    "- Liberal Party\n",
    "- Parti Quebecois\n",
    "- Coalition Avenir Quebec\n",
    "\n",
    "After researching the similarities between similarily named parties we realized some should be combined into one specific naming convention. Specifically, we will combine: \n",
    "- BC Liberal Party and Liberal Party into just Liberal Party\n",
    "- Progressive Conservative Party and United Conservative party into just Conservative Party\n",
    "\n",
    "Parti Quebecois and Coalition Avenir Quebec are very distinct in their policies and these will be kept separate as they are. Also, we will remove the accents above the e's in the Quebec party names. To perform this cleaning we present the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in data\n",
    "prov_df = pd.read_csv('Data/provincial_governments_2000_2024.csv')\n",
    "\n",
    "# Select columns to change\n",
    "columns_to_modify = [\n",
    "    'BC Provincial Government',\n",
    "    'Alberta Provincial Government',\n",
    "    'Ontario Provincial Government',\n",
    "    'Quebec Provincial Government'\n",
    "]\n",
    "\n",
    "# Identify specific replacements\n",
    "replacements = {\n",
    "    'BC Liberal Party': 'Liberal Party',\n",
    "    'Progressive Conservative Party': 'Conservative Party',\n",
    "    'United Conservative Party': 'Conservative Party',\n",
    "    'Parti Québécois': 'Parti Quebecois',\n",
    "    'Coalition Avenir Québec': 'Coalition Avenir Quebec'\n",
    "}\n",
    "\n",
    "# Apply changes\n",
    "prov_df[columns_to_modify] = prov_df[columns_to_modify].replace(replacements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, for compatibility we need to reorganize the layout of this dataset to be (Province, year, Government). We implement this with the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Province</th>\n",
       "      <th>Government</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>BritishColumbia</td>\n",
       "      <td>NDP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001</td>\n",
       "      <td>BritishColumbia</td>\n",
       "      <td>NDP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002</td>\n",
       "      <td>BritishColumbia</td>\n",
       "      <td>Liberal Party</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year         Province     Government\n",
       "0  2000  BritishColumbia            NDP\n",
       "1  2001  BritishColumbia            NDP\n",
       "2  2002  BritishColumbia  Liberal Party"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pivot the dataframe to suggested format\n",
    "df_long = pd.melt(prov_df, \n",
    "                  id_vars=['Year'], \n",
    "                  var_name='Province', \n",
    "                  value_name='Government')\n",
    "\n",
    "# Clean up column names\n",
    "df_long['Province'] = df_long['Province'].str.replace(' Provincial Government', '')\n",
    "df_long['Province'] = df_long['Province'].str.replace('BC', 'BritishColumbia')\n",
    "\n",
    "\n",
    "# Write to csv\n",
    "df_long.to_csv('Data/Clean/provincial_governments_2000_2024.csv', index=False)\n",
    "\n",
    "# Display cleaned and formatted data\n",
    "df_long.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Set 2: Percent Health Expenditure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we look to clean the data set regarding provincial health expenditure per year percent increase across all provinces. This data set is particularly messy to begin with. We will perform the following operations to make the data suit our needs:\n",
    "\n",
    "- Remove rows 1 to 56 since they contain data only on total expenditure whereas we want percent increase/decrease in expenditure which is found on rows 56 and below\n",
    "- Remove rows past 105 since they contain other data we are not interested in\n",
    "- Remove columns which concern provinces we are not interested in\n",
    "- Remove rows from years outside of 2000 to 2024\n",
    "- Correct data types for all data since initial spreadsheet has all strings\n",
    "- Rename columns for better formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in data\n",
    "prov_spending_df = pd.read_csv('Data/nhex_prov_terr_data.csv', skiprows = 56, nrows = 49)\n",
    "\n",
    "# Select columns we care about\n",
    "columns_of_interest = [\n",
    "    \"Year\", \n",
    "    \"B.C.     \",\n",
    "    \"Alta.    \",\n",
    "    \"Ont.\",\n",
    "    \"Que.  \" \n",
    "]\n",
    "\n",
    "# Drop columns be do not care about\n",
    "prov_spending_df = prov_spending_df[columns_of_interest]\n",
    "\n",
    "# Convert data to correct types\n",
    "prov_spending_df[\"Year\"] = prov_spending_df[\"Year\"].astype(int)\n",
    "other_columns = prov_spending_df.columns.difference([\"Year\"])\n",
    "prov_spending_df[other_columns] = prov_spending_df[other_columns].astype(float)\n",
    "\n",
    "# Drop years we are not concerned with\n",
    "prov_spending_df = prov_spending_df[(prov_spending_df[\"Year\"] >= 2000)]\n",
    "\n",
    "prov_spending_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Rename columns\n",
    "prov_spending_df.rename(columns={\n",
    "    \"B.C.     \": \"BritishColumbia\",\n",
    "    \"Alta.    \": \"Alberta\",\n",
    "    \"Ont.\": \"Ontario\",\n",
    "    \"Que.  \": \"Quebec\"\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to ensure compatibility we reformat this dataset to the structure (province, year, percent_expenditure_change), we do this with the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Province</th>\n",
       "      <th>Percent_expenditure_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>BritishColumbia</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001</td>\n",
       "      <td>BritishColumbia</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002</td>\n",
       "      <td>BritishColumbia</td>\n",
       "      <td>6.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year         Province  Percent_expenditure_change\n",
       "0  2000  BritishColumbia                         9.2\n",
       "1  2001  BritishColumbia                        10.4\n",
       "2  2002  BritishColumbia                         6.4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pivot\n",
    "df_long_spending = pd.melt(prov_spending_df,\n",
    "                  id_vars=['Year'],\n",
    "                  var_name='Province',\n",
    "                  value_name='Percent_expenditure_change')\n",
    "\n",
    "# Write to csv\n",
    "df_long_spending.to_csv('Data/Clean/nhex_prov_terr_data.csv', index=False)\n",
    "\n",
    "# Display the cleaned and formatted data\n",
    "df_long_spending.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Set 3: Community Health Survey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the second research question we will need quantitative data on health care spending, as percent change in expenditure will not suffice. To do this, we will need to read only rows 112 to 160 in the Excel file, and we will have to convert all values to numerical in order to be able to perform operations on our data. To make this work, we will need to specify that this dataset uses commas to distinguish large values, which would normally be flagged as non-numeric. Finally, this data has some missing values for Nunavut, so we will convert these missing values into np.nan values. Once we have read the data, we will need to correct the column names as the raw data includes several spaces in the column names which will be problematic when we later need to merge datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>N.L.</th>\n",
       "      <th>P.E.I.</th>\n",
       "      <th>N.S.</th>\n",
       "      <th>N.B.</th>\n",
       "      <th>Quebec</th>\n",
       "      <th>Ontario</th>\n",
       "      <th>Man.</th>\n",
       "      <th>Sask.</th>\n",
       "      <th>Alberta</th>\n",
       "      <th>BritishColumbia</th>\n",
       "      <th>Y.T.</th>\n",
       "      <th>N.W.T</th>\n",
       "      <th>Nun.</th>\n",
       "      <th>Canada (Average)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1975.0</td>\n",
       "      <td>357.92</td>\n",
       "      <td>352.59</td>\n",
       "      <td>322.88</td>\n",
       "      <td>300.87</td>\n",
       "      <td>399.86</td>\n",
       "      <td>377.83</td>\n",
       "      <td>367.52</td>\n",
       "      <td>329.31</td>\n",
       "      <td>384.21</td>\n",
       "      <td>371.34</td>\n",
       "      <td>281.70</td>\n",
       "      <td>355.89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>376.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1976.0</td>\n",
       "      <td>389.23</td>\n",
       "      <td>382.68</td>\n",
       "      <td>362.39</td>\n",
       "      <td>351.60</td>\n",
       "      <td>464.68</td>\n",
       "      <td>429.35</td>\n",
       "      <td>435.49</td>\n",
       "      <td>390.82</td>\n",
       "      <td>434.15</td>\n",
       "      <td>427.29</td>\n",
       "      <td>393.11</td>\n",
       "      <td>427.60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>431.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1977.0</td>\n",
       "      <td>412.98</td>\n",
       "      <td>419.50</td>\n",
       "      <td>398.29</td>\n",
       "      <td>390.49</td>\n",
       "      <td>508.18</td>\n",
       "      <td>462.03</td>\n",
       "      <td>479.36</td>\n",
       "      <td>434.85</td>\n",
       "      <td>451.21</td>\n",
       "      <td>464.19</td>\n",
       "      <td>444.82</td>\n",
       "      <td>525.96</td>\n",
       "      <td>NaN</td>\n",
       "      <td>467.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1978.0</td>\n",
       "      <td>455.02</td>\n",
       "      <td>463.22</td>\n",
       "      <td>438.04</td>\n",
       "      <td>427.56</td>\n",
       "      <td>568.57</td>\n",
       "      <td>492.35</td>\n",
       "      <td>504.31</td>\n",
       "      <td>468.12</td>\n",
       "      <td>504.61</td>\n",
       "      <td>521.51</td>\n",
       "      <td>492.42</td>\n",
       "      <td>619.82</td>\n",
       "      <td>NaN</td>\n",
       "      <td>512.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1979.0</td>\n",
       "      <td>521.43</td>\n",
       "      <td>508.78</td>\n",
       "      <td>486.34</td>\n",
       "      <td>478.80</td>\n",
       "      <td>632.25</td>\n",
       "      <td>527.10</td>\n",
       "      <td>549.26</td>\n",
       "      <td>529.79</td>\n",
       "      <td>600.00</td>\n",
       "      <td>583.99</td>\n",
       "      <td>538.34</td>\n",
       "      <td>610.04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>565.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year    N.L.  P.E.I.    N.S.    N.B.  Quebec  Ontario    Man.   Sask.  \\\n",
       "0  1975.0  357.92  352.59  322.88  300.87  399.86   377.83  367.52  329.31   \n",
       "1  1976.0  389.23  382.68  362.39  351.60  464.68   429.35  435.49  390.82   \n",
       "2  1977.0  412.98  419.50  398.29  390.49  508.18   462.03  479.36  434.85   \n",
       "3  1978.0  455.02  463.22  438.04  427.56  568.57   492.35  504.31  468.12   \n",
       "4  1979.0  521.43  508.78  486.34  478.80  632.25   527.10  549.26  529.79   \n",
       "\n",
       "   Alberta  BritishColumbia    Y.T.   N.W.T  Nun.  Canada (Average)  \n",
       "0   384.21           371.34  281.70  355.89   NaN            376.32  \n",
       "1   434.15           427.29  393.11  427.60   NaN            431.98  \n",
       "2   451.21           464.19  444.82  525.96   NaN            467.93  \n",
       "3   504.61           521.51  492.42  619.82   NaN            512.01  \n",
       "4   600.00           583.99  538.34  610.04   NaN            565.94  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nhex_percapita = pd.read_csv('https://raw.githubusercontent.com/RibbitsM/368-research-proj/refs/heads/main/Data/nhex_prov_terr_data.csv',\n",
    "                        header=112, skiprows=lambda x: x > 160, dtype=np.float64, thousands=',', na_values='—')\n",
    "nhex_percapita.columns = ['Year', 'N.L.', 'P.E.I.', 'N.S.', 'N.B.', 'Quebec', 'Ontario', 'Man.', 'Sask.', 'Alberta', \n",
    "                        'BritishColumbia', 'Y.T.', 'N.W.T', 'Nun.', 'Canada (Average)']\n",
    "nhex_percapita.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will read in the data from the 2019-2020 community health survey. This is a very broad survey with almost 700 variables, but only a few are relevant to our analysis. Based on the documentation, we have selected the province of the respondant, as well as their responses to several questions related to the quality and efficiency of the health they have received or lack access to. All of these variables are originally categorical, and we will keep them in their numerical encodings so that we can aggregate them later on in the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Version of given Stata file is 118. pandas supports importing versions 105, 108, 111 (Stata 7SE), 113 (Stata 8/9), 114 (Stata 10/11), 115 (Stata 12), 117 (Stata 13), 118 (Stata 14/15/16),and 119 (Stata 15/16, over 32,767 variables).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m keep_attributes \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeogprv\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPHC_060\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPHC_035\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPHC_005\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPHC_020\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUCN_005\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m cchs_data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_stata\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mData/cchs_201920_pumf.dta\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_attributes\u001b[49m\u001b[43m,\u001b[49m\u001b[43mconvert_categoricals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m cchs_data\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/miniforge3/envs/cpsc368/lib/python3.9/site-packages/pandas/io/stata.py:2109\u001b[0m, in \u001b[0;36mread_stata\u001b[0;34m(filepath_or_buffer, convert_dates, convert_categoricals, index_col, convert_missing, preserve_dtypes, columns, order_categoricals, chunksize, iterator, compression, storage_options)\u001b[0m\n\u001b[1;32m   2106\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m reader\n\u001b[1;32m   2108\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m reader:\n\u001b[0;32m-> 2109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/cpsc368/lib/python3.9/site-packages/pandas/io/stata.py:1683\u001b[0m, in \u001b[0;36mStataReader.read\u001b[0;34m(self, nrows, convert_dates, convert_categoricals, index_col, convert_missing, preserve_dtypes, columns, order_categoricals)\u001b[0m\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_read_method_doc)\n\u001b[1;32m   1672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(\n\u001b[1;32m   1673\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1681\u001b[0m     order_categoricals: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1682\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m-> 1683\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ensure_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1685\u001b[0m     \u001b[38;5;66;03m# Handle options\u001b[39;00m\n\u001b[1;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_dates \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/cpsc368/lib/python3.9/site-packages/pandas/io/stata.py:1175\u001b[0m, in \u001b[0;36mStataReader._ensure_open\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1171\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1172\u001b[0m \u001b[38;5;124;03mEnsure the file has been opened and its header data read.\u001b[39;00m\n\u001b[1;32m   1173\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_path_or_buf\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1175\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/cpsc368/lib/python3.9/site-packages/pandas/io/stata.py:1205\u001b[0m, in \u001b[0;36mStataReader._open_file\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1202\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_path_or_buf \u001b[38;5;241m=\u001b[39m BytesIO(handles\u001b[38;5;241m.\u001b[39mhandle\u001b[38;5;241m.\u001b[39mread())\n\u001b[1;32m   1203\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_path_or_buf\u001b[38;5;241m.\u001b[39mclose\n\u001b[0;32m-> 1205\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_header\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1206\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setup_dtype()\n",
      "File \u001b[0;32m~/miniforge3/envs/cpsc368/lib/python3.9/site-packages/pandas/io/stata.py:1287\u001b[0m, in \u001b[0;36mStataReader._read_header\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1285\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_new_header()\n\u001b[1;32m   1286\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1287\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_old_header\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfirst_char\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/cpsc368/lib/python3.9/site-packages/pandas/io/stata.py:1453\u001b[0m, in \u001b[0;36mStataReader._read_old_header\u001b[0;34m(self, first_char)\u001b[0m\n\u001b[1;32m   1451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_version \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(first_char[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m   1452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_version \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m104\u001b[39m, \u001b[38;5;241m105\u001b[39m, \u001b[38;5;241m108\u001b[39m, \u001b[38;5;241m111\u001b[39m, \u001b[38;5;241m113\u001b[39m, \u001b[38;5;241m114\u001b[39m, \u001b[38;5;241m115\u001b[39m]:\n\u001b[0;32m-> 1453\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(_version_error\u001b[38;5;241m.\u001b[39mformat(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_version))\n\u001b[1;32m   1454\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_encoding()\n\u001b[1;32m   1455\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_byteorder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m>\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_int8() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0x1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: Version of given Stata file is 118. pandas supports importing versions 105, 108, 111 (Stata 7SE), 113 (Stata 8/9), 114 (Stata 10/11), 115 (Stata 12), 117 (Stata 13), 118 (Stata 14/15/16),and 119 (Stata 15/16, over 32,767 variables)."
     ]
    }
   ],
   "source": [
    "keep_attributes = ['geogprv','PHC_060','PHC_035','PHC_005','PHC_020','UCN_005']\n",
    "cchs_data = pd.read_stata(\"Data/cchs_201920_pumf.dta\", columns=keep_attributes,convert_categoricals=False)\n",
    "cchs_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will notice that this means that the province of the respondant is also numerically encoded, which we will adjust to match the encoding from the health expenditure dataset for simplicity. Also, we will group and summarize our dataset to get the average responses to each question per province, to make comparisons across provinces easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prov_dict = {47:\"Sask.\",59:'BritishColumbia',13:'N.B.',46:'Man.',35:'Ontario',12:'N.S.',24:'Quebec',10:'N.L.', \n",
    "            48: 'Alberta', 11: 'P.E.I.', 60: 'Terrs.'}\n",
    "cchs_data['geogprv'] = cchs_data['geogprv'].replace(prov_dict)\n",
    "\n",
    "cchs_data_avg = cchs_data.groupby('geogprv',axis=0).mean().round(3).reset_index()\n",
    "cchs_data_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To match our survey data, we will need to select the expenditure data from only the years of the survey, which happen to be 2019 and 2020. Also, the community survey does not distinguish between data collected in Nunavut or the Yukon and Northwest Territories, and as such we will have to aggregate the per capita expenditure of all three territories into a single column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_year_expenditure = nhex_percapita[44:46]\n",
    "survey_year_expenditure['Terrs.'] = ((survey_year_expenditure['Y.T.'] + survey_year_expenditure['N.W.T'] +\n",
    "                                    survey_year_expenditure['Nun.'])/3)\n",
    "survey_year_expenditure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to merge our datasets we will need to drop the original territories columns, as well as the Year and Canada Average columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_year_expenditure = survey_year_expenditure.drop(['Year', 'Canada (Average)','Y.T.','N.W.T','Nun.'], axis=1)\n",
    "survey_year_expenditure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will pivot our dataframe and aggregate the values to get the average per capita expenditure for each province across 2019 and 2020 as a column, and the province name as another column. This is the proper formatting that will allow us to perform a natural join with our survey data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhex_pivot = survey_year_expenditure.melt(var_name='geogprv',value_name='avg_percap_spend'\n",
    "                                        ).groupby('geogprv').mean().round(3).reset_index()\n",
    "nhex_pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the merge function, we can finally join our two datasets together to get a dataframe that can be used for visualize our research question. Keep in mind we still have some NaN values, unfortunately not all survey questions were asked in all provinces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = nhex_pivot.merge(cchs_data_avg, on='geogprv')\n",
    "combined_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "In this section we will take a closer look at the trends in our data to gain insight that we can use before further analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we will look at is the frequency of each party. To do this we will first plot a histogram of the parties and then a histogram of party by province."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the clean data of provincial governments in power by year\n",
    "prov_df = pd.read_csv('Data/Clean/provincial_governments_2000_2024.csv')\n",
    "\n",
    "# Drop year column\n",
    "parties_df = prov_df.drop(columns=['Year','Province'])\n",
    "\n",
    "# Create single list for all occurences of parties\n",
    "all_parties = parties_df.values.ravel()\n",
    "\n",
    "# Count occurences of each party\n",
    "party_counts = pd.Series(all_parties).value_counts()\n",
    "\n",
    "# Plot frequency of each party being in power\n",
    "party_counts.plot(kind='bar', color='skyblue', edgecolor='black')\n",
    "plt.title('Figure 1: Frequency of Each Party Being in Power')\n",
    "plt.xlabel('Party')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate labels for clarity if needed\n",
    "plt.tight_layout()  # Ensures labels/titles fit nicely\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From figure 1 above we can see that the Liberal Party is very well represented in our data whereas Coalition Avenir Quebec and Parti Quebecois are not. This is critical information to know since for our first research question we will be using hpyothesis testing and if there are not many samples for certain groups then our power will be very low. As a result of this we may end up exluding Quebec as a province in our analysis so we can focus on more mainstream parties in Canada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our next visualization we will look into the data on percent change in expenditure for public health. We will plot The percent change in expenditure for each province over the timeline of the datas set to see if there is much of a difference between provinces over the past 24 years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the cleaned data\n",
    "expenditure_df = pd.read_csv('Data/Clean/nhex_prov_terr_data.csv')\n",
    "\n",
    "# Create a figure\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot a line for each province\n",
    "for province, group in expenditure_df.groupby('Province'):\n",
    "    plt.plot(group['Year'], group['Percent_expenditure_change'], marker='o', label=province)\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Figure 2: Historical Expenditure Change by Province')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Percent Expenditure Change')\n",
    "plt.legend(title='Province')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The visualization in figure 2 lets us see if each province generally maintains the same trends in healthcare spending. This will give us insight into whether government type really does affect percent increase in expenditure for public health and this graph does just that. We can see a general trend in spending, but there exist differences between provinces which is crucial. Further, it is interesting to note that we can clearly see the spike due to the Covid-19 pandemic. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the second research question, our dataset only has a few variables in it so we should be able to fit all of them into one comprehensive visualization, or at least a set of visualizations. We're going to make several scatterplots with a survey variable on the x axis and the per capita spending on the y axis with the points coloured by province, which should hopefully give an indication of any correlations or patterns in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PHC_060_chart = alt.Chart(combined_data).mark_circle().encode(\n",
    "    alt.X('PHC_060').scale(domain=[1, 3.5]),\n",
    "    alt.Y('avg_percap_spend').scale(domain=[4000, 13000]),\n",
    "    alt.Color('geogprv'))\n",
    "\n",
    "PHC_035_chart = alt.Chart(combined_data, title=\"Figure 3: Average Expenditure per Capita by Province and Survey Metric\").mark_circle().encode(\n",
    "    alt.X('PHC_035').scale(domain=[1, 4.5]),\n",
    "    alt.Y('avg_percap_spend').scale(domain=[4000, 13000]),\n",
    "    alt.Color('geogprv'))\n",
    "\n",
    "PHC_005_chart = alt.Chart(combined_data).mark_circle().encode(\n",
    "    alt.X('PHC_005').scale(domain=[1, 1.2]),\n",
    "    alt.Y('avg_percap_spend').scale(domain=[4000, 13000]),\n",
    "    alt.Color('geogprv'))\n",
    "\n",
    "PHC_020_chart = alt.Chart(combined_data).mark_circle().encode(\n",
    "    alt.X('PHC_020').scale(domain=[1, 1.5]),\n",
    "    alt.Y('avg_percap_spend').scale(domain=[4000, 13000]),\n",
    "    alt.Color('geogprv'))\n",
    "\n",
    "UCN_005_chart = alt.Chart(combined_data).mark_circle().encode(\n",
    "    alt.X('UCN_005').scale(domain=[1, 2.1]),\n",
    "    alt.Y('avg_percap_spend').scale(domain=[4000, 13000]),\n",
    "    alt.Color('geogprv'))\n",
    "\n",
    "PHC_060_chart & PHC_020_chart | PHC_035_chart & UCN_005_chart | PHC_005_chart "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the chart in case it doesn't appear on Github:\n",
    "\n",
    "![visualization](visualization.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results fom our EDA Process\n",
    "\n",
    "In figure 1 we saw the underrepresentation of 2 parties in Quebec. From this we will likely exclude Quebec as a province in parts of our analysis since the number of samples is likely too small to make meaningful conclusion with. This will change the way we handle our data since we will have to end up exluding Quebec during our analysis later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a couple important things to note with figure 3. First of all, it seems like some variables have much more variation between provinces compared to others. Specifically, PHC_020 (Access to regular health provider), PHC_060 (Coordination between health providers), and PHC_035 (Waiting time for minor health issues) seem to be particularly spread out. There are also two notable outliers, in Newfoundland and Labrador and particularly the Territories. Both of these regions have significantly higher spending per capita and while there isn't as clear of a trend in the survey variables, they tend to stick towards the right end of the graph, which indicates poorer health care as the most positive encoding for each variable is 1. Especially with access to regular health provider, this disparity is extremely notable. While this is like a product of geography and not a bias because of the smaller population, it would probably be worth it adding the total expenditure for each province as another variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhex_total = pd.read_csv('https://raw.githubusercontent.com/RibbitsM/368-research-proj/refs/heads/main/Data/nhex_prov_terr_data.csv',\n",
    "                        header=4, skiprows=lambda x: x > 51, dtype=np.float64, thousands=',', na_values='—')\n",
    "nhex_total.columns = ['Year', 'N.L.', 'P.E.I.', 'N.S.', 'N.B.', 'Quebec', 'Ontario', 'Man.', 'Sask.', 'Alberta', \n",
    "                        'BritishColumbia', 'Y.T.', 'N.W.T', 'Nun.', 'Canada (Average)']\n",
    "total_year = nhex_total[44:46]\n",
    "total_year['Terrs'] = ((total_year['Y.T.'] + total_year['N.W.T'] +\n",
    "                                    total_year['Nun.'])/3)\n",
    "total_year = total_year.drop(['Year', 'Canada (Average)','Y.T.','N.W.T','Nun.'], axis=1)\n",
    "total_pivot = total_year.melt(var_name='geogprv',value_name='avg_total_spend'\n",
    "                                        ).groupby('geogprv').mean().round(3).reset_index()\n",
    "combined_total = combined_data.merge(total_pivot, on='geogprv')\n",
    "combined_total['Year'] = ['2019','2019','2019','2019','2019','2019','2019','2019','2019','2019']\n",
    "combined_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all this done, we should finally be ready to move on and save this data to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_total.to_csv(\"Data/Clean/nhexandcchs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will need to generate the SQL script to insert this data into a database. This function takes a path to a cleaned csv file, the name of the sql file to be created, and the name of an SQL table and generates a text file containing insert statements to insert all data within the provided csv file into an SQL table. This also works with nan values which will automatically be converted to sql Null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_sql(\"Data/Clean/provincial_governments_2000_2024.csv\",\"SQL/provincial_governments_2000_2024.sql\", \"provincial_governments\")\n",
    "make_sql(\"Data/Clean/nhex_prov_terr_data.csv\",\"SQL/nhex_prov_terr_data.sql\", \"percent_expenditure_change\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schema for our Database\n",
    "\n",
    "The schema of our database is as follows:\n",
    "\n",
    "- provincial_governments(Province, Year, Party), Primary Key(Province, Year)\n",
    "- percent_expenditure_change(Province, Year, percent_expenditure_change), Primary Key(Province, Year), Foreign Key(Province, Year) referencing provincial_governments\n",
    "- survey_expenditure(Province, PerCapSpend, Coordination, WaitingTime, CareAccess, ProviderAccess, UnmetNeeds, TotalSpend, Year), Primary Key (Province) \n",
    "PerCapSpend, Coordination, WaitingTime, CareAccess, ProviderAccess, TotalSpend, and Year are all not null.\n",
    "\n",
    "This schema may at first seem redundant since we could combine all our data into one table but there are a few reasons why this implementation is useful. Firstly, each table is concerned with conceptually distinct data. If we were to combine them all then it would be not obvious what the specific use of the table is. Also, this layout offers increases flexibility. Since each table concerns a distinct data set to begin with, the amount of updates and the frequency of them is likely to be different in the future and this schema allows for that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL\n",
    "\n",
    "We created an sql file titled healthcare.sql that when run creates all tables with the appropriate schema and inserts all of our cleaned data. We made a function make_sql() which automatically creates the necessary insert statments which can be found below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sql(input_file, output_file, table_name):\n",
    "    data = pd.read_csv(input_file)\n",
    "    with open(output_file, \"w\") as f:\n",
    "        f.write(\"\")\n",
    "    for index, row in data.iterrows():\n",
    "        with open(output_file, \"a\") as f:\n",
    "            f.write(\"\\ninsert into \" + table_name + \" \\nvalues(\")\n",
    "            for item in range(data.shape[1]):\n",
    "                if item == data.shape[1] - 1:\n",
    "                    if str(row[item]) == 'nan':\n",
    "                        f.write(\"NULL\"+', ')\n",
    "                    else:\n",
    "                        f.write(\"'\"+str(row[item])+\"'\"+');\\n')\n",
    "                else:\n",
    "                    if str(row[item]) == 'nan':\n",
    "                        f.write(\"NULL\"+', ')\n",
    "                    else:\n",
    "                        f.write(\"'\"+str(row[item])+\"'\"+', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An example of running the script\n",
    "make_sql(\"Data/Clean/provincial_governments_2000_2024.csv\",\"SQL/provincial_governments_2000_2024.sql\", \"provincial_governments\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The crate table statements are listed below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREATE TABLE provincial_governments (\n",
    "    year INT,\n",
    "    province VARCHAR(50),\n",
    "    party VARCHAR(50),\n",
    "    PRIMARY KEY (year, province)\n",
    "    PRIMARY KEY (year, province)\n",
    ");\n",
    "\n",
    "CREATE TABLE percent_expenditure_change (\n",
    "    year INT,\n",
    "    province VARCHAR(50),\n",
    "    percent_expenditure_change NUMERIC(5,2),\n",
    "    PRIMARY KEY (year, province),\n",
    "    FOREIGN KEY (year, province)\n",
    "        REFERENCES provincial_governments(year, province)\n",
    ");\n",
    "\n",
    "CREATE TABLE survey_expenditure (\n",
    "    idx int,\n",
    "    province VARCHAR(15),\n",
    "    per_cap_spend FLOAT(10),\n",
    "    coordination FLOAT(5),\n",
    "    waiting_time FLOAT(5),\n",
    "    care_access FLOAT(5),\n",
    "    provider_access FLOAT(5),\n",
    "    unmet_needs FLOAT(5),\n",
    "    total_spend FLOAT(10) NOT NULL,\n",
    "    year INT NOT NULL,\n",
    "    PRIMARY KEY (province)\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our full, working healthcare.sql file will be submitted separately with this report."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
